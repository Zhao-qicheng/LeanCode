# LeanCode ç¯å¢ƒé…ç½®è¯´æ˜

## âœ… ç¯å¢ƒé…ç½®å·²å®Œæˆ

### ğŸ“¦ å·²å®‰è£…çš„ä¾èµ–

æ‰€æœ‰å¿…éœ€çš„ä¾èµ–åº“å·²æˆåŠŸå®‰è£…åœ¨ `leancode` conda ç¯å¢ƒä¸­ï¼š

| åº“å | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| Python | 3.11.5 | ç¼–ç¨‹è¯­è¨€ |
| PyTorch | 2.0.1 (CUDA 11.7) | æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| Transformers | 4.25.1 | HuggingFaceæ¨¡å‹åº“ |
| NumPy | 1.23.5 | æ•°å€¼è®¡ç®— |
| tqdm | 4.64.1 | è¿›åº¦æ¡ |
| TensorBoard | 2.11.2 | è®­ç»ƒå¯è§†åŒ– |
| thop | 0.1.1 | æ¨¡å‹å‚æ•°è®¡ç®— |
| gdown | 4.6.0 | Google Driveä¸‹è½½ |
| scikit-learn | 1.3.0 | æœºå™¨å­¦ä¹ å·¥å…· |

### ğŸ® GPU ä¿¡æ¯

- **GPUæ•°é‡**: 2å—
- **GPUå‹å·**: NVIDIA GeForce RTX 4090
- **æ˜¾å­˜**: æ¯å— 24GB
- **CUDAç‰ˆæœ¬**: 11.7

## ğŸš€ å¦‚ä½•ä½¿ç”¨

### 1. æ¿€æ´»ç¯å¢ƒ

æ¯æ¬¡ä½¿ç”¨å‰ï¼Œéœ€è¦å…ˆæ¿€æ´»condaç¯å¢ƒï¼š

```bash
conda activate leancode
```

### 2. éªŒè¯ç¯å¢ƒ

è¿è¡ŒéªŒè¯è„šæœ¬ç¡®è®¤ç¯å¢ƒé…ç½®æ­£ç¡®ï¼š

```bash
python verify_env.py
```

### 3. ä¸‹è½½æ•°æ®é›†

æŒ‰ç…§README.mdä¸­çš„è¯´æ˜ä¸‹è½½æ•°æ®é›†ï¼š

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/codesearch data/code2nl

# ä¸‹è½½ä»£ç æœç´¢æ•°æ®é›†
cd data/codesearch
gdown https://drive.google.com/uc?id=1xgSR34XO8xXZg4cZScDYj2eGerBE9iGo
unzip codesearch_data.zip
rm codesearch_data.zip

# ä¸‹è½½ä»£ç æ‘˜è¦æ•°æ®é›†
cd ../code2nl
gdown https://drive.google.com/uc?id=1rd2Tc6oUWBo7JouwexW3ksQ0PaOhUr6h
unzip Cleaned_CodeSearchNet.zip
rm Cleaned_CodeSearchNet.zip
cd ../..

# å‡†å¤‡SlimCodeæµ‹è¯•æ•°æ®
cd slimcode
mkdir -p data/codesearch data/code2nl
cd ..
python utils/process_slimcode.py
gunzip data/codesearch/java_test_0.jsonl.gz
python codesearch/process_data.py
```

### 4. å¼€å§‹è®­ç»ƒ

#### ä»£ç æœç´¢ä»»åŠ¡ (CodeBERT)

```bash
python3 codesearch/run_classifier.py \
  --model_type roberta \
  --tokenizer_name microsoft/codebert-base \
  --model_name_or_path microsoft/codebert-base \
  --task_name codesearch \
  --do_train --do_eval \
  --prune_strategy None \
  --output_dir ./models/codesearch/codebert/base \
  --data_dir ./data/codesearch/train_valid/java \
  --train_file train.txt \
  --dev_file valid.txt \
  --max_seq_length 512 \
  --per_gpu_train_batch_size 64 \
  --per_gpu_eval_batch_size 64 \
  --learning_rate 1e-5 \
  --num_train_epochs 4 \
  --lang java \
  --gradient_accumulation_steps 1 \
  --overwrite_output_dir
```

#### ä»£ç æ‘˜è¦ä»»åŠ¡ (CodeT5)

```bash
python code2nl/CodeT5/run_gen.py \
  --model_type codet5 \
  --task summarize \
  --sub_task java \
  --tokenizer_name Salesforce/codet5-base \
  --model_name_or_path Salesforce/codet5-base \
  --do_train --do_eval --do_eval_bleu \
  --prune_strategy None \
  --data_num -1 \
  --num_train_epochs 8 \
  --warmup_steps 1000 \
  --learning_rate 5e-5 \
  --patience 2 \
  --data_dir ./data/code2nl/CodeSearchNet/java \
  --cache_path ./models/code2nl/codet5/base/cache_data \
  --output_dir ./models/code2nl/codet5/base \
  --save_last_checkpoints \
  --always_save_model \
  --res_dir ./models/code2nl/codet5/base/prediction \
  --res_fn ./models/code2nl/codet5/base/result.txt \
  --train_batch_size 96 \
  --eval_batch_size 96 \
  --max_source_length 512 \
  --max_target_length 128 \
  --summary_dir ./models/code2nl/codet5/base/tensorboard
```

### 5. ä½¿ç”¨å‘½ä»¤ç”Ÿæˆå™¨

é¡¹ç›®æä¾›äº†ä¾¿æ·çš„å‘½ä»¤ç”Ÿæˆå·¥å…·ï¼š

```bash
# ç¤ºä¾‹ï¼šCodeBERT + LeanCodeç­–ç•¥ + 40%å‰ªæç‡
python utils/gen_cmd.py \
  --task_type codesearch \
  --model_type codebert \
  --prune_strategy leancode \
  --prune_ratio 40

# åŸºç¡€å®éªŒï¼ˆä¸å‰ªæï¼‰
python utils/gen_cmd.py \
  --task_type codesearch \
  --model_type codebert \
  --prune_strategy None
```

**å‚æ•°è¯´æ˜**ï¼š
- `task_type`: `codesearch` (ä»£ç æœç´¢) æˆ– `code2nl` (ä»£ç æ‘˜è¦)
- `model_type`: `codebert` æˆ– `codet5`
- `prune_strategy`: `leancode`, `slimcode`, `dietcode`, `leancode_d`, æˆ– `None`
- `prune_ratio`: `10`, `20`, `30`, `40`, `50` (ç™¾åˆ†æ¯”)

## ğŸ’¡ å¸¸ç”¨å‘½ä»¤

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate leancode

# é€€å‡ºç¯å¢ƒ
conda deactivate

# æŸ¥çœ‹å·²å®‰è£…çš„åŒ…
pip list

# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# æŸ¥çœ‹ç¯å¢ƒåˆ—è¡¨
conda env list
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡ä½¿ç”¨æ¨¡å‹**ï¼šé¦–æ¬¡è¿è¡Œæ—¶ä¼šä»HuggingFaceè‡ªåŠ¨ä¸‹è½½CodeBERTå’ŒCodeT5æ¨¡å‹ï¼Œéœ€è¦ç½‘ç»œè¿æ¥
2. **å¤šGPUè®­ç»ƒ**ï¼šé¡¹ç›®ä¼šè‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUè¿›è¡Œè®­ç»ƒ
3. **å†…å­˜ç®¡ç†**ï¼šå¦‚æœé‡åˆ°OOMé”™è¯¯ï¼Œå¯ä»¥å‡å°batch_size
4. **æ•°æ®è·¯å¾„**ï¼šç¡®ä¿æ•°æ®é›†è·¯å¾„ä¸å‘½ä»¤ä¸­çš„è·¯å¾„ä¸€è‡´

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1: CUDA out of memory
**è§£å†³æ–¹æ¡ˆ**: å‡å°batch size
```bash
--per_gpu_train_batch_size 32  # ä»64é™ä½åˆ°32
```

### é—®é¢˜2: æ¨¡å‹ä¸‹è½½å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**: 
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°åæŒ‡å®šè·¯å¾„

### é—®é¢˜3: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶
**è§£å†³æ–¹æ¡ˆ**: 
1. æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æ­£ç¡®ä¸‹è½½å’Œè§£å‹
2. éªŒè¯æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®

## ğŸ“š å‚è€ƒèµ„æº

- [é¡¹ç›®README](README.md)
- [PyTorchæ–‡æ¡£](https://pytorch.org/docs/stable/index.html)
- [Transformersæ–‡æ¡£](https://huggingface.co/docs/transformers)
- [CodeBERT](https://huggingface.co/microsoft/codebert-base)
- [CodeT5](https://huggingface.co/Salesforce/codet5-base)

---

**ç¯å¢ƒé…ç½®å®Œæˆæ—¶é—´**: 2025-10-22  
**é…ç½®è€…**: AIåŠ©æ‰‹

